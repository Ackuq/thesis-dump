{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83fa44ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th></tr><tr><td>38</td><td>application_1642582607798_0037</td><td>spark</td><td>idle</td><td><a target=\"_blank\" href=\"/hopsworks-api/yarnui/https://hopsworks0.logicalclocks.com:8089/proxy/application_1642582607798_0037/\">Link</a></td><td><a target=\"_blank\" href=\"/hopsworks-api/yarnui/https://hopsworks0.logicalclocks.com:8044/node/containerlogs/container_e03_1642582607798_0037_01_000001/demo_fs_meb10000__meb10000\">Link</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n",
      "import org.apache.spark.sql.{DataFrame, Row, SparkSession}\n",
      "import org.apache.spark.sql.types.{StructType, IntegerType, StringType, StructField}\n",
      "import org.apache.spark.sql.functions._\n",
      "import org.apache.spark.sql.expressions.Window\n",
      "import io.hops.util.Hops\n",
      "import io.github.ackuq.pit._\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.{DataFrame, Row, SparkSession}\n",
    "import org.apache.spark.sql.types.{StructType, IntegerType, StringType, StructField}\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.expressions.Window\n",
    "import io.hops.util.Hops\n",
    "import io.github.ackuq.pit._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea7b696a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_PATH: String = hdfs:///Projects/demo_fs_meb10000/Jupyter/PIT-joins/experiment/data/\n",
      "DATA_DIRECTORIES: Seq[String] = List(10000-1_year, 20000-1_year, 40000-1_year, 80000-1_year)\n"
     ]
    }
   ],
   "source": [
    "val BASE_PATH = \"hdfs:///Projects/\" + Hops.getProjectName + \"/Jupyter/PIT-joins/experiment/data/\"\n",
    "val DATA_DIRECTORIES = Seq(\"10000-1_year\", \"20000-1_year\", \"40000-1_year\", \"80000-1_year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f89e8627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labelData: org.apache.spark.sql.DataFrame = [id: bigint, ts: bigint ... 1 more field]\n",
      "featureData: org.apache.spark.sql.DataFrame = [id: bigint, ts: bigint ... 1 more field]\n"
     ]
    }
   ],
   "source": [
    "val labelData = spark.read.parquet(BASE_PATH + DATA_DIRECTORIES(0) + \"/left.parquet\")\n",
    "val featureData = spark.read.parquet(BASE_PATH + DATA_DIRECTORIES(0) + \"/right.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8cbf87b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unionPIT: (label: org.apache.spark.sql.DataFrame, features: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\n"
     ]
    }
   ],
   "source": [
    "def unionPIT(label: DataFrame, features: DataFrame): DataFrame = {\n",
    "    UnionAsOf.join(\n",
    "        label,\n",
    "        features,\n",
    "        leftPrefix = Some(\"df1_\"),\n",
    "        rightPrefix = \"df2_\",\n",
    "        partitionCols = Seq(\"id\")\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40fc20d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pitTest: org.apache.spark.sql.DataFrame = [id: bigint, df1_ts: bigint ... 3 more fields]\n"
     ]
    }
   ],
   "source": [
    "// Test the union PIT\n",
    "val pitTest = unionPIT(labelData, featureData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d003d00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featureData: org.apache.spark.sql.DataFrame = [id: bigint, ts: bigint ... 1 more field]\n",
      "+---+---+-----+\n",
      "| id| ts|value|\n",
      "+---+---+-----+\n",
      "+---+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val featureData = spark.read.parquet(BASE_PATH + DATA_DIRECTORIES(0) + \"/right.parquet\")\n",
    "\n",
    "featureData.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3aa9471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+---------+------+---------+\n",
      "|  id|  df1_ts|df1_label|df2_ts|df2_value|\n",
      "+----+--------+---------+------+---------+\n",
      "|  26|24685843|       26|  null|     null|\n",
      "|  29|10406545|       29|  null|     null|\n",
      "| 474|13385699|      474|  null|     null|\n",
      "| 964| 8806710|      964|  null|     null|\n",
      "|1677|18761519|     1677|  null|     null|\n",
      "|1697|23753009|     1697|  null|     null|\n",
      "|1806|10608320|     1806|  null|     null|\n",
      "|1950|10507013|     1950|  null|     null|\n",
      "|2040| 9222752|     2040|  null|     null|\n",
      "|2214| 6138051|     2214|  null|     null|\n",
      "|2250|13310809|     2250|  null|     null|\n",
      "|2453|11537917|     2453|  null|     null|\n",
      "|2509| 2333796|     2509|  null|     null|\n",
      "|2529| 6809193|     2529|  null|     null|\n",
      "|2927| 7458916|     2927|  null|     null|\n",
      "|3091|25861160|     3091|  null|     null|\n",
      "|3506|21356807|     3506|  null|     null|\n",
      "|3764|27585395|     3764|  null|     null|\n",
      "|4590|20714029|     4590|  null|     null|\n",
      "|4823| 4141623|     4823|  null|     null|\n",
      "+----+--------+---------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pitTest.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1f2ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark",
   "language": "scala",
   "name": "sparkkernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}